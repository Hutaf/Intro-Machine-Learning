{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "2.3_Demo_Rare_Values.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "geSmj4Fvhmcr",
        "outputId": "0ea3e962-b529-49a8-ba84-a4e534e11c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile rare_values.py\n",
        "\n",
        "import pandas as pd\n",
        "# import numpy as np\n",
        "# from warnings import warn\n",
        "\n",
        "# 2018.11.07 Created by Eamon.Zhang\n",
        "# 2018.11.12 change into fit() transform() format\n",
        "\n",
        "class GroupingRareValues():\n",
        "    \"\"\"\n",
        "    Grouping the observations that show rare labels into a unique category ('rare')\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "   \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mapping=None, cols=None, threshold=0.01):\n",
        "        self.cols = cols\n",
        "        self.mapping = mapping\n",
        "        self._dim = None\n",
        "        self.threshold = threshold\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None, **kwargs):\n",
        "        \"\"\"Fit encoder according to X and y.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            Training vectors, where n_samples is the number of samples\n",
        "            and n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "            Target values.\n",
        "        Returns\n",
        "        -------\n",
        "        self : encoder\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "\n",
        "        self._dim = X.shape[1]\n",
        "\n",
        "        _, categories = self.grouping(\n",
        "            X,\n",
        "            mapping=self.mapping,\n",
        "            cols=self.cols,\n",
        "            threshold=self.threshold\n",
        "        )\n",
        "        self.mapping = categories\n",
        "        return self\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Perform the transformation to new categorical data.\n",
        "        Will use the mapping (if available) and the column list to encode the\n",
        "        data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "        Returns\n",
        "        -------\n",
        "        X : Transformed values with encoding applied.\n",
        "        \"\"\"\n",
        "\n",
        "        if self._dim is None:\n",
        "            raise ValueError('Must train encoder before it can be used to transform data.')\n",
        "\n",
        "        #  make sure that it is the right size\n",
        "        if X.shape[1] != self._dim:\n",
        "            raise ValueError('Unexpected input dimension %d, expected %d' % (X.shape[1], self._dim,))\n",
        "\n",
        "        X, _ = self.grouping(\n",
        "            X,\n",
        "            mapping=self.mapping,\n",
        "            cols=self.cols,\n",
        "            threshold=self.threshold\n",
        "        )\n",
        "\n",
        "        return X \n",
        "\n",
        "\n",
        "    def grouping(self, X_in, threshold, mapping=None, cols=None):\n",
        "        \"\"\"\n",
        "        Grouping the observations that show rare labels into a unique category ('rare')\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        X = X_in.copy(deep=True)\n",
        "\n",
        "#        if cols is None:\n",
        "#            cols = X.columns.values\n",
        "\n",
        "        if mapping is not None:  # transform\n",
        "            mapping_out = mapping\n",
        "            for i in mapping:\n",
        "                column = i.get('col') # get the column name\n",
        "                X[column] = X[column].map(i['mapping'])\n",
        "\n",
        "#                try:\n",
        "#                    X[column] = X[column].astype(int)\n",
        "#                except ValueError as e:\n",
        "#                    X[column] = X[column].astype(float)\n",
        "        else: # fit\n",
        "            mapping_out = []\n",
        "            for col in cols:\n",
        "#                if util.is_category(X[col].dtype):\n",
        "#                    categories = X[col].cat.categories\n",
        "#                else:\n",
        "                temp_df = pd.Series(X[col].value_counts()/len(X))\n",
        "                mapping = { k: ('rare' if k not in temp_df[temp_df >= threshold].index else k)\n",
        "                          for k in temp_df.index}\n",
        "\n",
        "                mapping = pd.Series(mapping)\n",
        "                mapping_out.append({'col': col, 'mapping': mapping, 'data_type': X[col].dtype}, )\n",
        "\n",
        "        return X, mapping_out\n",
        "\n",
        "\n",
        "\n",
        "#==============================================================================\n",
        "# def rare_imputation(X_train, X_test, variable):\n",
        "#     \n",
        "#     # find the most frequent category\n",
        "#     frequent_cat = X_train.groupby(variable)[variable].count().sort_values().tail(1).index.values[0]\n",
        "#     \n",
        "#     # find rare labels\n",
        "#     temp = X_train.groupby([variable])[variable].count()/np.float(len(X_train))\n",
        "#     rare_cat = [x for x in temp.loc[temp<0.05].index.values]\n",
        "#     \n",
        "#     # create new variables, with Rare labels imputed\n",
        "#     \n",
        "#     # by the most frequent category\n",
        "#     X_train[variable+'_freq_imp'] = np.where(X_train[variable].isin(rare_cat), frequent_cat, X_train[variable])\n",
        "#     X_test[variable+'_freq_imp'] = np.where(X_test[variable].isin(rare_cat), frequent_cat, X_test[variable])\n",
        "#     \n",
        "#     # by adding a new label 'Rare'\n",
        "#     X_train[variable+'_rare_imp'] = np.where(X_train[variable].isin(rare_cat), 'Rare', X_train[variable])\n",
        "#     X_test[variable+'_rare_imp'] = np.where(X_test[variable].isin(rare_cat), 'Rare', X_test[variable])\n",
        "#==============================================================================\n",
        "\n",
        "# 2018.11.26 created by Eamon.Zhang\n",
        "class ModeImputation():\n",
        "    \"\"\"\n",
        "    Replacing the rare label by most frequent label\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "   \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mapping=None, cols=None, threshold=0.01):\n",
        "        self.cols = cols\n",
        "        self.mapping = mapping\n",
        "        self._dim = None\n",
        "        self.threshold = threshold\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None, **kwargs):\n",
        "        \"\"\"Fit encoder according to X and y.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            Training vectors, where n_samples is the number of samples\n",
        "            and n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "            Target values.\n",
        "        Returns\n",
        "        -------\n",
        "        self : encoder\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "\n",
        "        self._dim = X.shape[1]\n",
        "\n",
        "        _, categories = self.impute_with_mode(\n",
        "            X,\n",
        "            mapping=self.mapping,\n",
        "            cols=self.cols,\n",
        "            threshold=self.threshold\n",
        "        )\n",
        "        self.mapping = categories\n",
        "        return self\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Perform the transformation to new categorical data.\n",
        "        Will use the mapping (if available) and the column list to encode the\n",
        "        data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "        Returns\n",
        "        -------\n",
        "        X : Transformed values with encoding applied.\n",
        "        \"\"\"\n",
        "\n",
        "        if self._dim is None:\n",
        "            raise ValueError('Must train encoder before it can be used to transform data.')\n",
        "\n",
        "        #  make sure that it is the right size\n",
        "        if X.shape[1] != self._dim:\n",
        "            raise ValueError('Unexpected input dimension %d, expected %d' % (X.shape[1], self._dim,))\n",
        "\n",
        "        X, _ = self.impute_with_mode(\n",
        "            X,\n",
        "            mapping=self.mapping,\n",
        "            cols=self.cols,\n",
        "            threshold=self.threshold\n",
        "        )\n",
        "\n",
        "        return X \n",
        "\n",
        "\n",
        "    def impute_with_mode(self, X_in, threshold, mapping=None, cols=None):\n",
        "        \"\"\"\n",
        "        Grouping the observations that show rare labels into a unique category ('rare')\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        X = X_in.copy(deep=True)\n",
        "\n",
        "#        if cols is None:\n",
        "#            cols = X.columns.values\n",
        "\n",
        "        if mapping is not None:  # transform\n",
        "            mapping_out = mapping\n",
        "            for i in mapping:\n",
        "                column = i.get('col') # get the column name\n",
        "                X[column] = X[column].map(i['mapping'])\n",
        "\n",
        "#                try:\n",
        "#                    X[column] = X[column].astype(int)\n",
        "#                except ValueError as e:\n",
        "#                    X[column] = X[column].astype(float)\n",
        "        else: # fit\n",
        "            mapping_out = []\n",
        "            for col in cols:\n",
        "#                if util.is_category(X[col].dtype):\n",
        "#                    categories = X[col].cat.categories\n",
        "#                else:\n",
        "                temp_df = pd.Series(X[col].value_counts()/len(X))\n",
        "                median = X[col].mode()[0]\n",
        "                mapping = { k: (median if k not in temp_df[temp_df >= threshold].index else k)\n",
        "                          for k in temp_df.index}\n",
        "\n",
        "                mapping = pd.Series(mapping)\n",
        "                mapping_out.append({'col': col, 'mapping': mapping, 'data_type': X[col].dtype}, )\n",
        "\n",
        "        return X, mapping_out"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing rare_values.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reVCo1gvhkX4"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Lg9pGmhhtq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "import os\n",
        "# plt.style.use('seaborn-colorblind')\n",
        "# %matplotlib inline\n",
        "import rare_values as ra"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MX8dbN4hht0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi-b1foChht0",
        "outputId": "ca417667-0df8-47e7-ffa7-bc311fb2c035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "use_cols = [\n",
        "    'Pclass', 'Sex', 'Age', 'Fare', 'SibSp',\n",
        "    'Survived'\n",
        "]\n",
        "\n",
        "# see column Pclass & SibSp's distributions\n",
        "# SibSp has values 3/8/5 that occur rarely, under 2%\n",
        "# Pclass has 3 values, but no one is under 20%\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/daniel-dc-cd/feature-engineering-and-feature-selection/master/data/titanic.csv', usecols=use_cols)\n",
        "\n",
        "\n",
        "for i in ['Pclass','SibSp']:\n",
        "    print('Variable',i,'label proportion:')\n",
        "    print(data[i].value_counts()/len(data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable Pclass label proportion:\n",
            "3    0.551066\n",
            "1    0.242424\n",
            "2    0.206510\n",
            "Name: Pclass, dtype: float64\n",
            "Variable SibSp label proportion:\n",
            "0    0.682379\n",
            "1    0.234568\n",
            "2    0.031425\n",
            "4    0.020202\n",
            "3    0.017957\n",
            "8    0.007856\n",
            "5    0.005612\n",
            "Name: SibSp, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TttDtkeQhht3"
      },
      "source": [
        "## Grouping into one new category\n",
        "Grouping the observations that show rare labels into a unique category ('rare')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lx3NCCOhht4"
      },
      "source": [
        "# create the encoder and fit with our data\n",
        "enc = ra.GroupingRareValues(cols=['Pclass','SibSp'],threshold=0.01).fit(data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq9YThsAhht7",
        "outputId": "b614cf9b-5fd2-4f9b-c965-aa2cbb172f55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# let's see the mapping\n",
        "# for SibSp, values 5 & 8 are encoded as 'rare' as they appear less than 10%\n",
        "# for Pclass, nothing changed\n",
        "print(enc.mapping)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'col': 'Pclass', 'mapping': 3    3\n",
            "1    1\n",
            "2    2\n",
            "dtype: int64, 'data_type': dtype('int64')}, {'col': 'SibSp', 'mapping': 0       0\n",
            "1       1\n",
            "2       2\n",
            "4       4\n",
            "3       3\n",
            "8    rare\n",
            "5    rare\n",
            "dtype: object, 'data_type': dtype('int64')}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqm_Incshht9"
      },
      "source": [
        "# perform transformation\n",
        "data2 = enc.transform(data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfixqxNuhhuB",
        "outputId": "ad3851d1-ac6f-43d5-872d-93720f287d4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check the result\n",
        "print(data2.SibSp.value_counts())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       608\n",
            "1       209\n",
            "2        28\n",
            "4        18\n",
            "3        16\n",
            "rare     12\n",
            "Name: SibSp, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi_9TOs9hhuF"
      },
      "source": [
        "## Mode Imputation\n",
        "Replacing the rare label by most frequent label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfC5PdkRhhuF"
      },
      "source": [
        "# create the encoder and fit with our data\n",
        "enc = ra.ModeImputation(cols=['Pclass','SibSp'],threshold=0.01).fit(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhDKqWOJhhuI",
        "outputId": "68355131-c5ec-408a-eb9e-d9b55a4421ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# let's see the mapping\n",
        "# for SibSp, values 5 & 8 are encoded as 0, as label 0 is the most frequent label\n",
        "# for Pclass, nothing changed\n",
        "print(enc.mapping)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'col': 'Pclass', 'mapping': 3    3\n",
            "1    1\n",
            "2    2\n",
            "dtype: int64, 'data_type': dtype('int64')}, {'col': 'SibSp', 'mapping': 0    0\n",
            "1    1\n",
            "2    2\n",
            "4    4\n",
            "3    3\n",
            "8    0\n",
            "5    0\n",
            "dtype: int64, 'data_type': dtype('int64')}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1gBC9UZhhuL"
      },
      "source": [
        "# perform transformation\n",
        "data3 = enc.transform(data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ALLYMvfhhuO",
        "outputId": "f268ba5b-bc1f-4e05-c699-851b53fc71db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check the result\n",
        "print(data3.SibSp.value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    620\n",
            "1    209\n",
            "2     28\n",
            "4     18\n",
            "3     16\n",
            "Name: SibSp, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}